{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a888b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 1: Passo 2 - Carregamento de Dados e Data Augmentation (VERSÃO CORRIGIDA)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(f\"TensorFlow Versão: {tf.__version__}\")\n",
    "\n",
    "# --- 1. Definir Constantes e Caminhos ---\n",
    "IMG_SIZE = (224, 224) \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "data_dir = Path('../data/casting_data')\n",
    "train_dir = data_dir / 'train'\n",
    "test_dir = data_dir / 'test'\n",
    "\n",
    "if not train_dir.exists() or not test_dir.exists():\n",
    "    print(f\"Erro: Pastas de dados não encontradas.\")\n",
    "    print(f\"Verifique se a pasta 'casting_data' está em '{data_dir.parent}'\")\n",
    "else:\n",
    "    print(f\"Pasta de treino encontrada: {train_dir}\")\n",
    "    print(f\"Pasta de teste encontrada: {test_dir}\")\n",
    "\n",
    "# --- 2. Carregar Dados de Treino e Validação ---\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(f\"\\nClasses encontradas: {class_names}\") # ['def_front', 'ok_front']\n",
    "\n",
    "# --- 3. Camada de Data Augmentation (separada) ---\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomZoom(0.1),\n",
    "    ],\n",
    "    name=\"data_augmentation\"\n",
    ")\n",
    "\n",
    "# --- 4. Otimizar os Pipelines de Dados (COM A CORREÇÃO) ---\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "# Importar a função de pré-processamento\n",
    "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
    "\n",
    "def configure_for_performance(ds, augment=False, repeat=False):\n",
    "    ds = ds.cache()\n",
    "    if augment:\n",
    "        # Aplicar a augmentation SÓ no treino\n",
    "        ds = ds.map(lambda x, y: (data_augmentation(x), y), \n",
    "                    num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # Aplicar o pré-processamento (normalização [-1, 1]) EM TODOS\n",
    "    # Esta é a correção: mover a camada problemática para cá.\n",
    "    ds = ds.map(lambda x, y: (preprocess_input(x), y), \n",
    "                num_parallel_calls=AUTOTUNE)\n",
    "    \n",
    "    # CORREÇÃO: Adicionar .repeat() para o dataset de treino\n",
    "    if repeat:\n",
    "        ds = ds.repeat() # Isso corrige o 'UserWarning' do model.fit\n",
    "    \n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE) \n",
    "    return ds\n",
    "\n",
    "# Aplicar a configuração\n",
    "train_ds = configure_for_performance(train_ds, augment=True, repeat=True) # repeat=True\n",
    "val_ds = configure_for_performance(val_ds, augment=False, repeat=False)\n",
    "\n",
    "# --- 5. Preparar o Dataset de Teste ---\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    test_dir,\n",
    "    image_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False # Importante para a avaliação\n",
    ")\n",
    "# Aplicar a configuração no teste (sem augmentation, mas COM pré-processamento)\n",
    "test_ds = configure_for_performance(test_ds, augment=False, repeat=False)\n",
    "\n",
    "print(\"\\nPipelines de dados (train_ds, val_ds, test_ds) criados e otimizados.\")\n",
    "print(\"O pré-processamento (normalização) foi movido para o pipeline de dados.\")\n",
    "print(\"Passo 2 concluído com sucesso!\")\n",
    "\n",
    "# (Opcional) Visualizar imagens\n",
    "print(\"\\nVisualizando 9 imagens de treino (já pré-processadas e aumentadas):\")\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        # Reverter o pré-processamento (de [-1, 1] para [0, 1]) para visualização\n",
    "        img = (images[i].numpy() + 1) / 2 \n",
    "        plt.imshow(img)\n",
    "        plt.title(f\"{class_names[labels[i]]}\")\n",
    "        plt.axis(\"off\")\n",
    "plt.suptitle(\"Exemplo de Imagens de Treino (Pós-Augmentation e Pós-Processamento)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58a27bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 2: Passo 3 - Modelagem (Transfer Learning) e Passo 4 - Treinamento (VERSÃO CORRIGIDA v2)\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np # Certifique-se de que numpy está importado\n",
    "from pathlib import Path # Certifique-se de que Path está importado\n",
    "\n",
    "print(\"Iniciando Passo 3: Construção do Modelo (Transfer Learning)...\")\n",
    "\n",
    "# --- 3.1: Carregar o Modelo Base (MobileNetV2) ---\n",
    "# (Assumindo que IMG_SIZE foi definido na Célula 1 como (224, 224))\n",
    "base_model = MobileNetV2(\n",
    "    input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3),\n",
    "    include_top=False, \n",
    "    weights='imagenet'\n",
    ")\n",
    "\n",
    "# --- 3.2: Congelar o Modelo Base ---\n",
    "base_model.trainable = False\n",
    "print(f\"Modelo base (MobileNetV2) carregado e congelado.\")\n",
    "\n",
    "# --- 3.3: Criar a \"Cabeça\" de Classificação ---\n",
    "inputs = keras.Input(shape=(IMG_SIZE[0], IMG_SIZE[1], 3))\n",
    "x = base_model(inputs, training=False) \n",
    "x = layers.GlobalAveragePooling2D()(x) \n",
    "x = layers.Dropout(0.2)(x) \n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# --- 3.4: Compilar o Modelo ---\n",
    "model.compile(\n",
    "    loss='binary_crossentropy',\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"\\nModelo final construído e compilado (SEM camadas de pré-processamento).\")\n",
    "model.summary() \n",
    "\n",
    "print(\"\\nIniciando Passo 4: Treinamento do Modelo...\")\n",
    "\n",
    "# --- 4.1: Treinar ---\n",
    "initial_epochs = 20\n",
    "\n",
    "# --- CORREÇÃO: Usar .jpeg no glob e verificar caminhos ---\n",
    "# (Assumindo que train_dir e BATCH_SIZE foram definidos na Célula 1)\n",
    "try:\n",
    "    # Contar imagens .jpeg\n",
    "    train_image_files = list(train_dir.glob('*/*.jpeg'))\n",
    "    num_train_images = len(train_image_files)\n",
    "    \n",
    "    if num_train_images == 0:\n",
    "        print(f\"AVISO: Nenhuma imagem .jpeg encontrada em {train_dir} e suas subpastas.\")\n",
    "        # Tentar .jpg como fallback, caso a extensão seja diferente\n",
    "        train_image_files_jpg = list(train_dir.glob('*/*.jpg'))\n",
    "        if len(train_image_files_jpg) > 0:\n",
    "             print(\"Encontradas imagens .jpg. Usando essa contagem.\")\n",
    "             num_train_images = len(train_image_files_jpg)\n",
    "        else:\n",
    "             print(\"AVISO: Nenhuma imagem .jpg encontrada também.\")\n",
    "\n",
    "    print(f\"Total de imagens de treino encontradas: {num_train_images}\")\n",
    "\n",
    "    steps_per_epoch = int(np.ceil(num_train_images * 0.8 / BATCH_SIZE))\n",
    "    \n",
    "    # Calcular validation_steps baseado no número total de imagens no diretório de treino\n",
    "    # (Não precisamos re-glob, usamos o num_train_images que já temos)\n",
    "    validation_steps = int(np.ceil(num_train_images * 0.2 / BATCH_SIZE))\n",
    "\n",
    "    print(f\"Calculando steps: {steps_per_epoch} steps por época (treino)\")\n",
    "    print(f\"Calculando steps: {validation_steps} steps por época (validação)\")\n",
    "\n",
    "    # Verificar se os datasets train_ds e val_ds existem (da Célula 1)\n",
    "    if 'train_ds' not in locals() or 'val_ds' not in locals():\n",
    "        raise NameError(\"Datasets 'train_ds' ou 'val_ds' não encontrados. Execute a Célula 1.\")\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=initial_epochs,\n",
    "        steps_per_epoch=steps_per_epoch, \n",
    "        validation_data=val_ds,\n",
    "        validation_steps=validation_steps \n",
    "    )\n",
    "\n",
    "    print(\"\\nTreinamento concluído.\")\n",
    "\n",
    "    # --- 4.2: Salvar o Modelo Treinado ---\n",
    "    models_dir = Path('../models')\n",
    "    models_dir.mkdir(exist_ok=True) \n",
    "    model_path = models_dir / 'quality_control_model.h5'\n",
    "    model.save(model_path)\n",
    "    print(f\"Modelo (corrigido) salvo com sucesso em: {model_path}\")\n",
    "\n",
    "    # --- 4.3: Visualizar o Histórico de Treinamento ---\n",
    "    acc = history.history['accuracy']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(acc, label='Acurácia (Treino)')\n",
    "    plt.plot(val_acc, label='Acurácia (Validação)')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Acurácia do Treinamento e Validação')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Acurácia')\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(loss, label='Perda (Treino)')\n",
    "    plt.plot(val_loss, label='Perda (Validação)')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Perda (Loss) do Treinamento e Validação')\n",
    "    plt.xlabel('Época')\n",
    "    plt.ylabel('Perda')\n",
    "    plt.suptitle('Histórico do Treinamento (Modelo Corrigido)')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nPassos 3 e 4 concluídos com sucesso!\")\n",
    "\n",
    "except NameError as ne:\n",
    "    print(f\"\\nErro de Variável: {ne}\")\n",
    "    print(\"Certifique-se de que as variáveis IMG_SIZE, BATCH_SIZE, train_dir, train_ds, val_ds foram definidas na Célula 1.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcorreu um erro inesperado: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3475fc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 3: Passo 5 - Avaliação no Conjunto de Teste (VERSÃO CORRIGIDA)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Iniciando Passo 5 (Correção): Avaliação no Conjunto de Teste...\")\n",
    "\n",
    "# Verificar se as variáveis necessárias (da Célula 1 e 2) estão na memória\n",
    "if 'test_ds' not in locals() or 'model' not in locals() or 'class_names' not in locals():\n",
    "    print(\"Erro: Variáveis não encontradas.\")\n",
    "    print(\"Por favor, execute as Células 1 e 2 (corrigidas) primeiro.\")\n",
    "else:\n",
    "    # --- 5.1: Avaliação Final (Acurácia) ---\n",
    "    # Vamos avaliar o 'model' que ainda está na memória da Célula 2\n",
    "    \n",
    "    print(\"Avaliando o modelo treinado no conjunto de teste...\")\n",
    "    # 'test_ds' (da Célula 1) já está pré-processado, assim como o 'model' (da Célula 2) espera\n",
    "    loss, accuracy = model.evaluate(test_ds) \n",
    "\n",
    "    print(\"\\n--- Resultados da Avaliação no Conjunto de Teste ---\")\n",
    "    print(f\"  Acurácia (Accuracy): {accuracy * 100:.2f}%\")\n",
    "    print(f\"  Perda (Loss):        {loss:.4f}\")\n",
    "    print(\"--------------------------------------------------\")\n",
    "\n",
    "    # --- 5.2: Obter Predições e Rótulos Reais ---\n",
    "    print(\"\\nGerando predições para a Matriz de Confusão...\")\n",
    "\n",
    "    # Gerar predições para todo o conjunto de teste\n",
    "    y_pred_probs = model.predict(test_ds)\n",
    "    # Converter probabilidades (sigmoid) para classes (0 ou 1)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "    # Extrair os rótulos verdadeiros do dataset de teste\n",
    "    y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "    # --- AQUI ESTÁ A CORREÇÃO ---\n",
    "    # Usar a variável 'class_names' que definimos na Célula 1\n",
    "    target_names = class_names \n",
    "    print(f\"Classes (da Célula 1): {target_names}\") # ['def_front', 'ok_front']\n",
    "\n",
    "    # --- 5.3: Relatório de Classificação e Matriz de Confusão ---\n",
    "\n",
    "    print(\"\\n--- Relatório de Classificação (Classification Report) ---\")\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names)\n",
    "    print(report)\n",
    "\n",
    "    print(\"\\n--- Matriz de Confusão ---\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=target_names, \n",
    "                yticklabels=target_names)\n",
    "    plt.title('Matriz de Confusão (Dados de Teste)')\n",
    "    plt.ylabel('Rótulo Verdadeiro (Real)')\n",
    "    plt.xlabel('Rótulo Previsto (Modelo)')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nPasso 5 concluído com sucesso!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629affd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Célula 4: Passo 5 - Avaliação (VERSÃO CORRIGIDA)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Iniciando Passo 5 (Correção): Avaliação no Conjunto de Teste...\")\n",
    "\n",
    "# Verificar se as variáveis necessárias (da Célula 1 e 2) estão na memória\n",
    "if 'test_ds' not in locals() or 'model' not in locals() or 'class_names' not in locals():\n",
    "    print(\"Erro: Variáveis não encontradas.\")\n",
    "    print(\"Por favor, execute as Células 1 e 2 primeiro.\")\n",
    "else:\n",
    "    # --- 5.2: Obter Predições e Rótulos Reais ---\n",
    "    # (O model.predict e a acurácia da célula anterior já funcionaram)\n",
    "    \n",
    "    print(\"Gerando predições para a Matriz de Confusão...\")\n",
    "\n",
    "    # Obter as predições (saídas 'sigmoid' entre 0 e 1)\n",
    "    y_pred_probs = model.predict(test_ds)\n",
    "    \n",
    "    # Converter probabilidades para classes (0 ou 1)\n",
    "    y_pred = (y_pred_probs > 0.5).astype(\"int32\").flatten()\n",
    "\n",
    "    # Obter os rótulos verdadeiros (y_true) do test_ds\n",
    "    y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "    # --- AQUI ESTÁ A CORREÇÃO ---\n",
    "    # Usar a variável 'class_names' que definimos na Célula 1,\n",
    "    # em vez de 'test_ds.class_names'\n",
    "    target_names = class_names \n",
    "    print(f\"Classes (da Célula 1): {target_names}\")\n",
    "\n",
    "    # --- 5.3: Relatório de Classificação e Matriz de Confusão ---\n",
    "\n",
    "    print(\"\\n--- Relatório de Classificação (Classification Report) ---\")\n",
    "    report = classification_report(y_true, y_pred, target_names=target_names)\n",
    "    print(report)\n",
    "\n",
    "    print(\"\\n--- Matriz de Confusão ---\")\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    plt.figure(figsize=(7, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                xticklabels=target_names, \n",
    "                yticklabels=target_names)\n",
    "    plt.title('Matriz de Confusão (Dados de Teste)')\n",
    "    plt.ylabel('Rótulo Verdadeiro (Real)')\n",
    "    plt.xlabel('Rótulo Previsto (Modelo)')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"\\nPasso 5 concluído com sucesso!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
